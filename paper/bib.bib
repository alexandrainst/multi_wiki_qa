@misc{you2025vuejs,
  author = {Evan You},
  title = {{VueJS}},
  howpublished = {\url{https://github.com/vuejs/core}},
  year = {2025},
  note = {GitHub Repository, version {v3.6.0-alpha.2}, accessed 2025}
}

@misc{tsroten2024hanzidentifier,
  author = {tsroten},
  title = {{hanzidentifier}},
  howpublished = {\url{https://github.com/tsroten/hanzidentifier}},
  year = {2024},
  note = {GitHub Repository, version {v1.3.0}, accessed 2025}
}

@article{reid2024gemini,
  title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
  author={Reid, Machel and Savinov, Nikolay and Teplyashin, Denis and Lepikhin, Dmitry and Lillicrap, Timothy P and Alayrac, Jean-Baptiste and Soricut, Radu and Lazaridou, Angeliki and Firat, Orhan and Schrittwieser, Julian and others},
  journal={CoRR},
  year={2024}
}

@inproceedings{saattrup-nielsen-etal-2025-encoder,
    title = "Encoder vs Decoder: {Comparative} Analysis of Encoder and Decoder Language Models on Multilingual {NLU} Tasks",
    author = "Saattrup Nielsen, Dan  and
      Enevoldsen, Kenneth  and
      Schneider-Kamp, Peter",
    editor = "Johansson, Richard  and
      Stymne, Sara",
    booktitle = "Proceedings of the Joint 25th Nordic Conference on Computational Linguistics and 11th Baltic Conference on Human Language Technologies (NoDaLiDa/Baltic-HLT 2025)",
    month = mar,
    year = "2025",
    address = "Tallinn, Estonia",
    publisher = "University of Tartu Library",
    url = "https://aclanthology.org/2025.nodalida-1.60/",
    pages = "561--572",
    ISBN = "978-9908-53-109-0",
    abstract = "This paper explores the performance of encoder and decoder language models on multilingual Natural Language Understanding (NLU) tasks, with a broad focus on Germanic languages. Building upon the ScandEval benchmark, initially restricted to evaluating encoder models, we extend the evaluation framework to include decoder models. We introduce a method for evaluating decoder models on NLU tasks and apply it to the languages Danish, Swedish, Norwegian, Icelandic, Faroese, German, Dutch, and English. Through a series of experiments and analyses, we also address research questions regarding the comparative performance of encoder and decoder models, the impact of NLU task types, and the variation across language resources. Our findings reveal that encoder models can achieve significantly better NLU performance than decoder models despite having orders of magnitude fewer parameters. Additionally, we investigate the correlation between decoders and task performance via a UMAP analysis, shedding light on the unique capabilities of decoder and encoder models. This study contributes to a deeper understanding of language model paradigms in NLU tasks and provides valuable insights for model selection and evaluation in multilingual settings."
}

@article{weissenborn2017making,
  title={Making Neural QA as Simple as Possible but not Simpler},
  author={Weissenborn, Dirk and Wiese, Georg and Seiffe, Laura},
  journal={CoNLL 2017},
  pages={271},
  year={2017}
}

@inproceedings{jia2017adversarial,
  title={Adversarial Examples for Evaluating Reading Comprehension Systems},
  author={Jia, Robin and Liang, Percy},
  booktitle={Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  pages={2021--2031},
  year={2017}
}

@inproceedings{nielsen-2023-scandeval,
    title = "{S}cand{E}val: A Benchmark for {S}candinavian Natural Language Processing",
    author = "Nielsen, Dan",
    editor = {Alum{\"a}e, Tanel  and
      Fishel, Mark},
    booktitle = "Proceedings of the 24th Nordic Conference on Computational Linguistics (NoDaLiDa)",
    month = may,
    year = "2023",
    address = "T{\'o}rshavn, Faroe Islands",
    publisher = "University of Tartu Library",
    url = "https://aclanthology.org/2023.nodalida-1.20/",
    pages = "185--201",
    abstract = "This paper introduces a Scandinavian benchmarking platform, ScandEval, which can benchmark any pretrained model on four different tasks in the Scandinavian languages. The datasets used in two of the tasks, linguistic acceptability and question answering, are new. We develop and release a Python package and command-line interface, scandeval, which can benchmark any model that has been uploaded to the Hugging Face Hub, with reproducible results. Using this package, we benchmark more than 80 Scandinavian or multilingual models and present the results of these in an interactive online leaderboard, as well as provide an analysis of the results. The analysis shows that there is substantial cross-lingual transfer among the the Mainland Scandinavian languages (Danish, Swedish and Norwegian), with limited cross-lingual transfer between the group of Mainland Scandinavian languages and the group of Insular Scandinavian languages (Icelandic and Faroese). The benchmarking results also show that the investment in language technology in Norway and Sweden has led to language models that outperform massively multilingual models such as XLM-RoBERTa and mDeBERTaV3. We release the source code for both the package and leaderboard."
}

@misc{mistralsmall2025,
	title = {Mistral Small 3.1},
    author = {Mistral-AI},
	year = {2025},
	month = jul,
	note = {[Online; accessed 31. Jul. 2025]},
	url = {https://mistral.ai/news/mistral-small-3-1}
}

@article{grattafiori2024llama,
  title={The Llama 3 herd of models},
  author={Grattafiori, Aaron and Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Vaughan, Alex and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{comanici2025gemini,
  title={Gemini 2.5: Pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities},
  author={Comanici, Gheorghe and Bieber, Eric and Schaekermann, Mike and Pasupat, Ice and Sachdeva, Noveen and Dhillon, Inderjit and Blistein, Marcel and Ram, Ori and Zhang, Dan and Rosen, Evan and others},
  journal={arXiv preprint arXiv:2507.06261},
  year={2025}
}

@article{wang2024multilingual,
  title={Multilingual e5 text embeddings: A technical report},
  author={Wang, Liang and Yang, Nan and Huang, Xiaolong and Yang, Linjun and Majumder, Rangan and Wei, Furu},
  journal={arXiv preprint arXiv:2402.05672},
  year={2024}
}

@inproceedings{ruder2019unsupervised,
  title={Unsupervised cross-lingual representation learning},
  author={Ruder, Sebastian and S{\o}gaard, Anders and Vuli{\'c}, Ivan},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts},
  pages={31--38},
  year={2019}
}
